{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7263eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score and Scale Calculation Functions (matching viphl_strategy_scoring.py)\n",
    "\n",
    "def calculate_hl_byp_score(m, n, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False):\n",
    "    '''\n",
    "    Calculate normalized HL byP score (0-1) based on m,n parameters with power scaling\n",
    "    \n",
    "    Args:\n",
    "        m, n: pivot point window parameters (leftbars, rightbars)\n",
    "        k: power_scaling_factor for window size calculation\n",
    "        max_mn_cap: maximum cap for normalization\n",
    "        by_point_weight: base weight for pivot points\n",
    "        on_trend_ratio: multiplier for trending conditions\n",
    "        is_trending: whether this is a trending condition\n",
    "    \n",
    "    Returns:\n",
    "        final_score: normalized score in range [0, 1]\n",
    "    '''\n",
    "    # Normalize window size to 0-1 range using power scaling: (m**k + n**k) / (2 * max_mn_cap**k)\n",
    "    window_score = min((m**k + n**k) / (2 * (max_mn_cap ** k)), 1.0)\n",
    "    \n",
    "    # Apply weight multipliers and condition-specific normalization\n",
    "    if is_trending:\n",
    "        # Trending conditions are more significant with on_trend_ratio multiplier\n",
    "        weight_multiplier = by_point_weight * on_trend_ratio\n",
    "        max_possible_weight = by_point_weight * on_trend_ratio  # Trending-specific max\n",
    "    else:\n",
    "        # Normal conditions use base weight\n",
    "        weight_multiplier = by_point_weight\n",
    "        max_possible_weight = by_point_weight  # Normal-specific max\n",
    "    \n",
    "    # Final score incorporating weights (normalized to each condition's max)\n",
    "    final_score = min(window_score * weight_multiplier / max_possible_weight, 1.0)\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "\n",
    "def calculate_combined_score(high_score, low_score, high_score_scaling_factor, low_score_scaling_factor):\n",
    "    '''\n",
    "    Combine high and low scores with scaling factors\n",
    "    \n",
    "    Args:\n",
    "        high_score: score from high pivot point\n",
    "        low_score: score from low pivot point\n",
    "        high_score_scaling_factor: weight for high pivot contribution\n",
    "        low_score_scaling_factor: weight for low pivot contribution\n",
    "    \n",
    "    Returns:\n",
    "        combined_score: weighted average in range [0, 1]\n",
    "    '''\n",
    "    weighted_high = high_score * high_score_scaling_factor\n",
    "    weighted_low = low_score * low_score_scaling_factor\n",
    "    total_weight = high_score_scaling_factor + low_score_scaling_factor\n",
    "    combined_score = (weighted_high + weighted_low) / total_weight\n",
    "    \n",
    "    return combined_score\n",
    "\n",
    "\n",
    "def calculate_pnl_scale(combined_score):\n",
    "    '''\n",
    "    Maps combined_score (0-1) to PnL scale (1-3)\n",
    "    \n",
    "    Current: Linear relationship\n",
    "    Formula: scale = 1 + 2 * score\n",
    "    \n",
    "    Characteristics:\n",
    "    - Linear/proportional relationship between score and scale\n",
    "    - Constant growth rate across all score ranges\n",
    "    - Balanced reward structure\n",
    "    \n",
    "    Examples:\n",
    "    - score=0.0 → scale=1.00 (minimum)\n",
    "    - score=0.5 → scale=2.00 (midpoint)\n",
    "    - score=1.0 → scale=3.00 (maximum)\n",
    "    '''\n",
    "    # Linear scaling (current)\n",
    "    scale = 1.0 + 2.0 * combined_score\n",
    "    \n",
    "    # Alternative: Square root scaling (commented out)\n",
    "    # scale = 1.0 + 2.0 * (combined_score ** 0.5)\n",
    "    # Examples: score=0.1→1.63, score=0.5→2.41, score=1.0→3.00\n",
    "    \n",
    "    return scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jcd582vazb",
   "metadata": {},
   "source": [
    "# VipHL Strategy Scoring System\n",
    "\n",
    "This notebook demonstrates the score and scale calculation logic from `viphl_strategy_scoring.py`.\n",
    "\n",
    "## Complete Scoring Flow\n",
    "\n",
    "1. **HL byP Score Calculation** (`calculate_hl_byp_score`)\n",
    "   - Input: `m, n` (pivot window parameters), `k` (power scaling factor), `max_mn_cap` (normalization cap)\n",
    "   - Formula: `window_score = min((m^k + n^k) / (2 * max_mn_cap^k), 1.0)`\n",
    "   - Apply weight multipliers based on trending vs normal conditions\n",
    "   - Output: `final_score` in range [0, 1]\n",
    "\n",
    "2. **Combined Score** (`calculate_combined_score`)\n",
    "   - Combine high and low pivot scores with scaling factors\n",
    "   - Formula: `combined_score = (high_score * high_weight + low_score * low_weight) / total_weight`\n",
    "   - Output: `combined_score` in range [0, 1]\n",
    "\n",
    "3. **PnL Scale** (`calculate_pnl_scale`)\n",
    "   - **Current: Linear relationship**\n",
    "   - Formula: `scale = 1 + 2 * combined_score`\n",
    "   - Maps score [0, 1] to scale [1.0, 3.0]\n",
    "   - This scale is **directly multiplied** with percentage returns for all PnL calculations\n",
    "\n",
    "## Default Parameters (from run configuration)\n",
    "\n",
    "- `max_mn_cap = 12`\n",
    "- `power_scaling_factor (k) = 1.0` (linear)\n",
    "- `high_score_scaling_factor = 0.5`\n",
    "- `low_score_scaling_factor = 0.5`\n",
    "- `by_point_weight = 1`\n",
    "- `on_trend_ratio = 1` (no boost for trending)\n",
    "\n",
    "## Examples\n",
    "\n",
    "Run the cells below to see how different parameters affect the final PnL scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c4828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Score (m=14, n=14, normal): 0.6755\n",
      "Low Score (m=14, n=14, normal): 0.6755\n",
      "\n",
      "Combined Score: 0.6755\n",
      "PnL Scale: 2.3509\n",
      "\n",
      "This means PnL will be multiplied by 2.35x\n"
     ]
    }
   ],
   "source": [
    "# Test with default parameters from viphl_strategy_scoring.py\n",
    "# Default configuration values\n",
    "k = 1.1              # power_scaling_factor\n",
    "max_mn_cap = 20      # max_mn_cap (from run configuration)\n",
    "by_point_weight = 1  # base weight\n",
    "on_trend_ratio = 1   # on_trend_ratio (from run configuration)\n",
    "\n",
    "\n",
    "a = 14\n",
    "# Test parameters for high pivot (normal condition)\n",
    "m_high = a  # high_by_point_n\n",
    "n_high = a  # high_by_point_m\n",
    "\n",
    "# Test parameters for low pivot (normal condition)\n",
    "m_low = a  # low_by_point_n\n",
    "n_low = a  # low_by_point_m\n",
    "\n",
    "# Calculate scores for normal (non-trending) conditions\n",
    "high_score = calculate_hl_byp_score(m_high, n_high, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "low_score = calculate_hl_byp_score(m_low, n_low, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "\n",
    "print(f\"High Score (m={m_high}, n={n_high}, normal): {high_score:.4f}\")\n",
    "print(f\"Low Score (m={m_low}, n={n_low}, normal): {low_score:.4f}\")\n",
    "\n",
    "# Combine scores with scaling factors\n",
    "high_score_scaling_factor = 0.5  # from run configuration\n",
    "low_score_scaling_factor = 0.5   # from run configuration\n",
    "\n",
    "combined_score = calculate_combined_score(high_score, low_score, high_score_scaling_factor, low_score_scaling_factor)\n",
    "print(f\"\\nCombined Score: {combined_score:.4f}\")\n",
    "\n",
    "# Calculate PnL scale\n",
    "pnl_scale = calculate_pnl_scale(combined_score)\n",
    "print(f\"PnL Scale: {pnl_scale:.4f}\")\n",
    "print(f\"\\nThis means PnL will be multiplied by {pnl_scale:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with trending conditions\n",
    "print(\"=== Testing Trending vs Normal Conditions ===\\n\")\n",
    "\n",
    "# Test parameters for trending conditions (from strategy defaults)\n",
    "m_high_trend = 10  # high_by_point_n_on_trend\n",
    "n_high_trend = 10  # high_by_point_m_on_trend\n",
    "m_low_trend = 10   # low_by_point_n_on_trend\n",
    "n_low_trend = 10   # low_by_point_m_on_trend\n",
    "\n",
    "# Calculate scores for trending conditions\n",
    "high_score_trend = calculate_hl_byp_score(m_high_trend, n_high_trend, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=True)\n",
    "low_score_trend = calculate_hl_byp_score(m_low_trend, n_low_trend, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=True)\n",
    "\n",
    "print(f\"TRENDING High Score (m={m_high_trend}, n={n_high_trend}): {high_score_trend:.4f}\")\n",
    "print(f\"TRENDING Low Score (m={m_low_trend}, n={n_low_trend}): {low_score_trend:.4f}\")\n",
    "\n",
    "# Combine and calculate scale\n",
    "combined_score_trend = calculate_combined_score(high_score_trend, low_score_trend, high_score_scaling_factor, low_score_scaling_factor)\n",
    "pnl_scale_trend = calculate_pnl_scale(combined_score_trend)\n",
    "\n",
    "print(f\"TRENDING Combined Score: {combined_score_trend:.4f}\")\n",
    "print(f\"TRENDING PnL Scale: {pnl_scale_trend:.4f}\")\n",
    "\n",
    "print(\"\\n--- Comparison ---\")\n",
    "print(f\"Normal PnL Scale: {pnl_scale:.4f}x\")\n",
    "print(f\"Trending PnL Scale: {pnl_scale_trend:.4f}x\")\n",
    "print(f\"Difference: {pnl_scale_trend - pnl_scale:.4f}x ({((pnl_scale_trend/pnl_scale - 1)*100):.2f}% increase)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f567ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test how PnL scale changes with different window sizes (m=n)\n",
    "print(\"=== PnL Scale vs Window Size (m=n, Normal Conditions) ===\\n\")\n",
    "print(f\"Parameters: k={k}, max_mn_cap={max_mn_cap}, high_weight={high_score_scaling_factor}, low_weight={low_score_scaling_factor}\\n\")\n",
    "print(\"m=n | High Score | Low Score | Combined | PnL Scale\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i in range(4, 21):\n",
    "    m = n = i\n",
    "    \n",
    "    # Calculate scores for both high and low (assuming same m,n)\n",
    "    high_score_i = calculate_hl_byp_score(m, n, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    low_score_i = calculate_hl_byp_score(m, n, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    \n",
    "    # Combine scores\n",
    "    combined_score_i = calculate_combined_score(high_score_i, low_score_i, high_score_scaling_factor, low_score_scaling_factor)\n",
    "    \n",
    "    # Calculate PnL scale\n",
    "    pnl_scale_i = calculate_pnl_scale(combined_score_i)\n",
    "    \n",
    "    print(f\"{i:3d} | {high_score_i:10.4f} | {low_score_i:9.4f} | {combined_score_i:8.4f} | {pnl_scale_i:9.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"At max_mn_cap={max_mn_cap}: combined_score={combined_score_i:.4f}, scale={pnl_scale_i:.4f}x\")\n",
    "print(f\"Maximum possible scale: 3.00x (when combined_score=1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test effect of different power_scaling_factor (k) values\n",
    "print(\"=== Impact of Power Scaling Factor (k) ===\\n\")\n",
    "print(\"Testing with m=n=10, max_mn_cap=12\\n\")\n",
    "print(\"k value | Window Score | Combined Score | PnL Scale\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "m = n = 10\n",
    "test_k_values = [0.5, 0.8, 1.0, 1.2, 1.5, 2.0]\n",
    "\n",
    "for test_k in test_k_values:\n",
    "    # Calculate with different k values\n",
    "    high_score_k = calculate_hl_byp_score(m, n, test_k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    low_score_k = calculate_hl_byp_score(m, n, test_k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    \n",
    "    combined_score_k = calculate_combined_score(high_score_k, low_score_k, high_score_scaling_factor, low_score_scaling_factor)\n",
    "    pnl_scale_k = calculate_pnl_scale(combined_score_k)\n",
    "    \n",
    "    # Window score is the raw score before weighting\n",
    "    window_score = min((m**test_k + n**test_k) / (2 * (max_mn_cap ** test_k)), 1.0)\n",
    "    \n",
    "    print(f\"{test_k:7.1f} | {window_score:12.4f} | {combined_score_k:14.4f} | {pnl_scale_k:9.4f}x\")\n",
    "\n",
    "print(\"\\nNote:\")\n",
    "print(\"- k < 1.0: Diminishing returns (slower growth)\")\n",
    "print(\"- k = 1.0: Linear relationship\")\n",
    "print(\"- k > 1.0: Exponential growth (rewards larger windows more)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3kxm5gr0gtm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete example: Different high/low window sizes showing weighting effect\n",
    "print(\"=== Complete Example: Different High/Low Window Sizes ===\\n\")\n",
    "\n",
    "# Scenario 1: Larger high window, smaller low window\n",
    "print(\"Scenario 1: High window (m=12, n=12), Low window (m=8, n=8)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "m_high_1 = 12\n",
    "n_high_1 = 12\n",
    "m_low_1 = 8\n",
    "n_low_1 = 8\n",
    "\n",
    "high_score_1 = calculate_hl_byp_score(m_high_1, n_high_1, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "low_score_1 = calculate_hl_byp_score(m_low_1, n_low_1, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "\n",
    "print(f\"High Score (m={m_high_1}, n={n_high_1}): {high_score_1:.4f}\")\n",
    "print(f\"Low Score (m={m_low_1}, n={n_low_1}): {low_score_1:.4f}\")\n",
    "\n",
    "# Test with different weighting\n",
    "for high_w, low_w in [(0.5, 0.5), (0.7, 0.3), (0.3, 0.7)]:\n",
    "    cs = calculate_combined_score(high_score_1, low_score_1, high_w, low_w)\n",
    "    ps = calculate_pnl_scale(cs)\n",
    "    print(f\"  Weights ({high_w:.1f}, {low_w:.1f}): Combined={cs:.4f}, Scale={ps:.4f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Scenario 2: Equal windows\n",
    "print(\"\\nScenario 2: Equal windows (m=10, n=10)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "m_high_2 = 10\n",
    "n_high_2 = 10\n",
    "m_low_2 = 10\n",
    "n_low_2 = 10\n",
    "\n",
    "high_score_2 = calculate_hl_byp_score(m_high_2, n_high_2, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "low_score_2 = calculate_hl_byp_score(m_low_2, n_low_2, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "\n",
    "print(f\"High Score (m={m_high_2}, n={n_high_2}): {high_score_2:.4f}\")\n",
    "print(f\"Low Score (m={m_low_2}, n={n_low_2}): {low_score_2:.4f}\")\n",
    "\n",
    "cs_2 = calculate_combined_score(high_score_2, low_score_2, 0.5, 0.5)\n",
    "ps_2 = calculate_pnl_scale(cs_2)\n",
    "print(f\"Combined Score: {cs_2:.4f}\")\n",
    "print(f\"PnL Scale: {ps_2:.4f}x\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Key Insight: Weighting allows emphasizing high or low pivot quality when they differ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57kbc153kev",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test effect of different high/low score weighting\n",
    "print(\"=== Impact of High/Low Score Weighting ===\\n\")\n",
    "print(\"Testing with m_high=n_high=10, m_low=n_low=10\\n\")\n",
    "print(\"High Weight | Low Weight | Combined Score | PnL Scale\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "m = n = 10\n",
    "weight_combinations = [\n",
    "    (1.0, 0.0),  # Only high matters\n",
    "    (0.75, 0.25),\n",
    "    (0.5, 0.5),  # Equal weight (current default)\n",
    "    (0.25, 0.75),\n",
    "    (0.0, 1.0),  # Only low matters\n",
    "]\n",
    "\n",
    "for high_weight, low_weight in weight_combinations:\n",
    "    # Calculate individual scores\n",
    "    hs = calculate_hl_byp_score(m, n, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    ls = calculate_hl_byp_score(m, n, k, max_mn_cap, by_point_weight, on_trend_ratio, is_trending=False)\n",
    "    \n",
    "    # Combine with different weights\n",
    "    cs = calculate_combined_score(hs, ls, high_weight, low_weight) if (high_weight + low_weight) > 0 else 0.0\n",
    "    ps = calculate_pnl_scale(cs)\n",
    "    \n",
    "    print(f\"{high_weight:11.2f} | {low_weight:10.2f} | {cs:14.4f} | {ps:9.4f}x\")\n",
    "\n",
    "print(\"\\nNote: With equal window sizes (m=n), weighting has no effect.\")\n",
    "print(\"Weighting matters when high and low pivots have different m,n values.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
